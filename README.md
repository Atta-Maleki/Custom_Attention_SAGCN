# Custom_Attention_SAGCN
A Huge AGCN based Neural Network containing Attention Channels
A large dataset trained an accurate model.


AGCN blocks were one of the effective innovations in Neural Networks. With having some changes on the AGCN adding some extra poolings and some other tools better results were achieved. 

The Architecture of the model with and without Attention channels added:

![Architecture with adding Attention Channels] ()

![Architecture without adding Attention Channels] ()
